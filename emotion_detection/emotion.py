"""
æƒ…ç·’æª¢æ¸¬ç³»çµ± - åŸºæ–¼ DeepFace
æ•´åˆç‰ˆæœ¬ - é«˜æº–ç¢ºåº¦æƒ…ç·’è­˜åˆ¥
"""
import os
import cv2
import numpy as np
from collections import deque
from deepface import DeepFace
from PIL import Image, ImageDraw, ImageFont


# ============================================
# é…ç½®åƒæ•¸ (å¯åœ¨æ­¤èª¿æ•´)
# ============================================

# æª¢æ¸¬å™¨é¸æ“‡
# é¸é …: 'opencv' (å¿«é€Ÿ), 'ssd', 'mtcnn' (æº–ç¢º,éœ€å®‰è£), 'retinaface' (æœ€æº–ç¢º,éœ€å®‰è£), 'mediapipe'
DETECTOR_BACKEND = 'opencv'

# å¹³æ»‘çª—å£å¤§å° (å¹€æ•¸) - è¶Šå¤§è¶Šç©©å®šä½†åæ‡‰è¶Šæ…¢
SMOOTH_WINDOW = 15

# ç½®ä¿¡åº¦é–¾å€¼ (0-100) - åªé¡¯ç¤ºè¶…éæ­¤å€¼çš„æƒ…ç·’
CONFIDENCE_THRESHOLD = 30

# è™•ç†é–“éš” (æ¯ N å¹€åˆ†æä¸€æ¬¡) - è¶Šå¤§è¶Šå¿«ä½†æ›´æ–°è¶Šæ…¢
PROCESS_EVERY_N_FRAMES = 2

# æ”åƒé ­è§£æåº¦
CAMERA_WIDTH = 1280
CAMERA_HEIGHT = 720

# æƒ…ç·’æ˜ å°„ (è‹±æ–‡ -> ç¹é«”ä¸­æ–‡)
EMOTION_MAP = {
    'angry': 'ğŸ˜  ç”Ÿæ°£',
    'disgust': 'ğŸ¤¢ å™å¿ƒ',
    'fear': 'ğŸ˜¨ å®³æ€•',
    'happy': 'ğŸ˜Š é–‹å¿ƒ',
    'sad': 'ğŸ˜¢ é›£é',
    'surprise': 'ğŸ˜² é©šè¨',
    'neutral': 'ğŸ˜ å¹³éœ'
}


# ============================================
# å·¥å…·å‡½æ•¸
# ============================================

def find_chinese_font():
    """å°‹æ‰¾ç³»çµ±ä¸­çš„ä¸­æ–‡å­—é«”"""
    # Windows å¸¸è¦‹ä¸­æ–‡å­—é«”
    fonts = [
        r'C:\Windows\Fonts\msjh.ttc',      # å¾®è»Ÿæ­£é»‘é«”
        r'C:\Windows\Fonts\msjhbd.ttc',
        r'C:\Windows\Fonts\mingliu.ttc',   # ç´°æ˜é«”
        r'C:\Windows\Fonts\simsun.ttc',    # å®‹é«”
        r'C:\Windows\Fonts\simhei.ttf',    # é»‘é«”
    ]
    
    for font in fonts:
        if os.path.exists(font):
            return font
    
    # å˜—è©¦æƒæå­—é«”ç›®éŒ„
    fonts_dir = r'C:\Windows\Fonts'
    try:
        if os.path.isdir(fonts_dir):
            for f in os.listdir(fonts_dir):
                lf = f.lower()
                if any(k in lf for k in ('noto', 'msj', 'ming', 'kai', 'sim', 'hei')):
                    full = os.path.join(fonts_dir, f)
                    if os.path.exists(full):
                        return full
    except Exception:
        pass
    
    return None


def draw_chinese_text(img, text, position, font_path, font_size=30, color=(255, 255, 255)):
    """åœ¨åœ–åƒä¸Šç¹ªè£½ä¸­æ–‡æ–‡å­—"""
    if not font_path:
        # å¦‚æœæ²’æœ‰ä¸­æ–‡å­—é«”,ä½¿ç”¨ OpenCV (åƒ…æ”¯æ´è‹±æ–‡)
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 
                   font_size/30, color, 2)
        return img
    
    # è½‰æ›ç‚º PIL åœ–åƒ
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # è¼‰å…¥å­—é«”
    try:
        font = ImageFont.truetype(font_path, font_size)
    except:
        return img
    
    # ç¹ªè£½æ–‡å­—
    draw.text(position, text, font=font, fill=color)
    
    # è½‰å› OpenCV æ ¼å¼
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)


# ============================================
# æƒ…ç·’æª¢æ¸¬å™¨é¡
# ============================================

class EmotionDetector:
    """æƒ…ç·’æª¢æ¸¬å™¨é¡ - å°è£æ‰€æœ‰æƒ…ç·’æª¢æ¸¬é‚è¼¯"""
    
    def __init__(self, detector_backend='opencv', smooth_window=15, confidence_threshold=30):
        """
        åˆå§‹åŒ–æƒ…ç·’æª¢æ¸¬å™¨
        
        Args:
            detector_backend: æª¢æ¸¬å™¨é¡å‹ ('opencv', 'ssd', 'mtcnn', 'retinaface', 'mediapipe')
            smooth_window: å¹³æ»‘çª—å£å¤§å° (å»ºè­° 10-20)
            confidence_threshold: ç½®ä¿¡åº¦é–¾å€¼ (å»ºè­° 25-40)
        """
        self.detector_backend = detector_backend
        self.smooth_window = smooth_window
        self.confidence_threshold = confidence_threshold
        self.emotion_buffer = deque(maxlen=smooth_window)
        self.font_path = find_chinese_font()
        self.last_face_region = None
        
        print(f"åˆå§‹åŒ–æƒ…ç·’æª¢æ¸¬å™¨...")
        print(f"  æª¢æ¸¬å™¨: {detector_backend}")
        print(f"  å¹³æ»‘çª—å£: {smooth_window} å¹€")
        print(f"  ç½®ä¿¡åº¦é–¾å€¼: {confidence_threshold}%")
        
        # é è¼‰å…¥æ¨¡å‹
        self._warmup()
    
    def _warmup(self):
        """é ç†±æ¨¡å‹"""
        try:
            print("  æ­£åœ¨è¼‰å…¥ DeepFace æ¨¡å‹...")
            dummy = np.zeros((100, 100, 3), dtype=np.uint8)
            DeepFace.analyze(
                dummy,
                actions=['emotion'],
                enforce_detection=False,
                detector_backend=self.detector_backend,
                silent=True
            )
            print("  âœ“ æ¨¡å‹è¼‰å…¥å®Œæˆ!")
        except Exception as e:
            print(f"  âš  æ¨¡å‹é è¼‰å…¥è­¦å‘Š: {e}")
    
    def analyze_frame(self, frame):
        """
        åˆ†æå–®å¹€åœ–åƒçš„æƒ…ç·’
        
        Args:
            frame: OpenCV BGR æ ¼å¼çš„åœ–åƒ
            
        Returns:
            dict: åŒ…å«æƒ…ç·’åˆ†æçµæœ,æˆ– None
        """
        try:
            # ä½¿ç”¨ DeepFace åˆ†æ
            result = DeepFace.analyze(
                frame,
                actions=['emotion'],
                enforce_detection=True,
                detector_backend=self.detector_backend,
                silent=True
            )
            
            # è™•ç†è¿”å›çµæœ
            if isinstance(result, list):
                result = result[0]
            
            return result
            
        except Exception as e:
            # æ²’æœ‰æª¢æ¸¬åˆ°è‡‰éƒ¨æˆ–å…¶ä»–éŒ¯èª¤
            return None
    
    def get_smoothed_emotion(self):
        """
        ç²å–å¹³æ»‘å¾Œçš„æƒ…ç·’çµæœ
        
        Returns:
            tuple: (æƒ…ç·’æ¨™ç±¤, ç½®ä¿¡åº¦, æ‰€æœ‰æƒ…ç·’åˆ†æ•¸) æˆ– None
        """
        if len(self.emotion_buffer) == 0:
            return None
        
        # ä½¿ç”¨æŒ‡æ•¸åŠ æ¬Šç§»å‹•å¹³å‡ (æœ€è¿‘çš„çµæœæ¬Šé‡æ›´é«˜)
        weights = np.exp(np.linspace(0, 2, len(self.emotion_buffer)))
        weights = weights / weights.sum()
        
        # ç´¯åŠ æƒ…ç·’åˆ†æ•¸
        emotion_sum = {}
        for i, emotion_dict in enumerate(self.emotion_buffer):
            for emotion, score in emotion_dict.items():
                if emotion not in emotion_sum:
                    emotion_sum[emotion] = 0
                emotion_sum[emotion] += score * weights[i]
        
        # æ‰¾å‡ºä¸»å°æƒ…ç·’
        dominant_emotion = max(emotion_sum.items(), key=lambda x: x[1])
        emotion_label, confidence = dominant_emotion
        
        # åªæœ‰ç•¶ç½®ä¿¡åº¦è¶…éé–¾å€¼æ‰è¿”å›
        if confidence >= self.confidence_threshold:
            return emotion_label, confidence, emotion_sum
        
        return None
    
    def process_frame(self, frame):
        """
        è™•ç†è¦–é »å¹€ä¸¦è¿”å›å¸¶æ¨™è¨»çš„åœ–åƒ
        
        Args:
            frame: åŸå§‹ OpenCV åœ–åƒ
            
        Returns:
            annotated_frame: å¸¶æƒ…ç·’æ¨™è¨»çš„åœ–åƒ
        """
        # åˆ†ææƒ…ç·’
        result = self.analyze_frame(frame)
        
        if result and 'emotion' in result:
            self.emotion_buffer.append(result['emotion'])
            self.last_face_region = result.get('region', {})
        
        # ç¹ªè£½çµæœ
        annotated = frame.copy()
        
        # ç¹ªè£½è‡‰éƒ¨æ¡†
        if self.last_face_region:
            x = self.last_face_region.get('x', 0)
            y = self.last_face_region.get('y', 0)
            w = self.last_face_region.get('w', 0)
            h = self.last_face_region.get('h', 0)
            
            # ç¶ è‰²æ¡†
            cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)
        
        # ç²å–å¹³æ»‘å¾Œçš„æƒ…ç·’
        emotion_result = self.get_smoothed_emotion()
        
        # ç¹ªè£½æƒ…ç·’ä¿¡æ¯
        self._draw_emotion_info(annotated, emotion_result)
        
        return annotated
    
    def _draw_emotion_info(self, img, emotion_result):
        """åœ¨åœ–åƒä¸Šç¹ªè£½æƒ…ç·’ä¿¡æ¯"""
        h, w = img.shape[:2]
        
        # å‰µå»ºåŠé€æ˜èƒŒæ™¯
        overlay = img.copy()
        
        if emotion_result:
            emotion_label, confidence, all_emotions = emotion_result
            
            # ä¸»è¦æƒ…ç·’é¡¯ç¤ºå€åŸŸ
            main_height = 80
            cv2.rectangle(overlay, (0, 0), (w, main_height), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.6, img, 0.4, 0, img)
            
            # ä¸»è¦æƒ…ç·’æ–‡å­—
            emotion_cn = EMOTION_MAP.get(emotion_label, emotion_label)
            main_text = f"{emotion_cn}  {confidence:.1f}%"
            
            if self.font_path:
                img[:] = draw_chinese_text(img, main_text, (20, 15), 
                                          self.font_path, font_size=40, 
                                          color=(255, 255, 255))
            else:
                cv2.putText(img, f"{emotion_label.upper()} {confidence:.1f}%", 
                           (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
            
            # è©³ç´°æƒ…ç·’åˆ†æ•¸ (å³å´)
            sorted_emotions = sorted(all_emotions.items(), key=lambda x: -x[1])
            
            detail_x = w - 280
            detail_y_start = 100
            bar_width = 250
            bar_height = 25
            
            for i, (emo, score) in enumerate(sorted_emotions[:5]):
                y_pos = detail_y_start + i * 40
                
                # ç¹ªè£½é€²åº¦æ¢èƒŒæ™¯
                cv2.rectangle(img, (detail_x, y_pos), 
                            (detail_x + bar_width, y_pos + bar_height), 
                            (50, 50, 50), -1)
                
                # ç¹ªè£½é€²åº¦æ¢
                bar_length = int((score / 100) * bar_width)
                color = (0, 255, 0) if emo == emotion_label else (100, 100, 100)
                cv2.rectangle(img, (detail_x, y_pos), 
                            (detail_x + bar_length, y_pos + bar_height), 
                            color, -1)
                
                # æƒ…ç·’æ¨™ç±¤
                emo_text = EMOTION_MAP.get(emo, emo)
                if self.font_path:
                    img[:] = draw_chinese_text(img, f"{emo_text} {score:.1f}%", 
                                              (detail_x + 5, y_pos + 2), 
                                              self.font_path, font_size=18,
                                              color=(255, 255, 255))
                else:
                    cv2.putText(img, f"{emo} {score:.0f}%", 
                               (detail_x + 5, y_pos + 18),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        else:
            # æ²’æœ‰æª¢æ¸¬åˆ°æƒ…ç·’
            status_height = 60
            cv2.rectangle(overlay, (0, 0), (w, status_height), (0, 0, 100), -1)
            cv2.addWeighted(overlay, 0.7, img, 0.3, 0, img)
            
            buffer_size = len(self.emotion_buffer)
            if buffer_size == 0:
                status_text = "æ­£åœ¨åµæ¸¬è‡‰éƒ¨..."
            elif buffer_size < self.smooth_window // 2:
                status_text = f"æ­£åœ¨æ”¶é›†æ•¸æ“š {buffer_size}/{self.smooth_window}"
            else:
                status_text = "ç½®ä¿¡åº¦ä¸è¶³,è«‹ä¿æŒæ˜é¡¯è¡¨æƒ…"
            
            if self.font_path:
                img[:] = draw_chinese_text(img, status_text, (20, 12), 
                                          self.font_path, font_size=30,
                                          color=(255, 255, 255))
            else:
                cv2.putText(img, "Detecting...", (20, 40),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
        
        # åº•éƒ¨ä¿¡æ¯æ¬„
        info_text = f"Buffer: {len(self.emotion_buffer)}/{self.smooth_window} | Detector: {self.detector_backend}"
        cv2.rectangle(img, (0, h - 30), (w, h), (0, 0, 0), -1)
        cv2.putText(img, info_text, (10, h - 8),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)


# ============================================
# ä¸»ç¨‹åº
# ============================================

def main():
    """ä¸»ç¨‹åº"""
    print("="*60)
    print("æƒ…ç·’æª¢æ¸¬ç³»çµ± - åŸºæ–¼ DeepFace")
    print("="*60)
    print()
    
    # åˆå§‹åŒ–æª¢æ¸¬å™¨
    try:
        detector = EmotionDetector(
            detector_backend=DETECTOR_BACKEND,
            smooth_window=SMOOTH_WINDOW,
            confidence_threshold=CONFIDENCE_THRESHOLD
        )
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±æ•—: {e}")
        print("å˜—è©¦ä½¿ç”¨é»˜èª opencv æª¢æ¸¬å™¨...")
        detector = EmotionDetector(
            detector_backend='opencv',
            smooth_window=SMOOTH_WINDOW,
            confidence_threshold=CONFIDENCE_THRESHOLD
        )
    
    # é–‹å•Ÿæ”åƒé ­
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("éŒ¯èª¤: ç„¡æ³•é–‹å•Ÿæ”åƒé ­")
        return
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    
    print("\n" + "="*60)
    print("ç³»çµ±å•Ÿå‹•æˆåŠŸ!")
    print("æç¤º:")
    print("  - é¢å‘æ”åƒé ­,ä¿æŒè¡¨æƒ…æ˜é¡¯")
    print("  - ç¢ºä¿å…‰ç·šå……è¶³")
    print("  - æŒ‰ 'q' é€€å‡ºç¨‹åº")
    print("="*60 + "\n")
    
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("ç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
                break
            
            frame_count += 1
            
            # æ¯ N å¹€è™•ç†ä¸€æ¬¡
            if frame_count % PROCESS_EVERY_N_FRAMES == 0:
                annotated_frame = detector.process_frame(frame)
            else:
                # ä¸è™•ç†æ™‚ä»ç„¶ç¹ªè£½ä¸Šæ¬¡çš„çµæœ
                annotated_frame = frame.copy()
                emotion_result = detector.get_smoothed_emotion()
                detector._draw_emotion_info(annotated_frame, emotion_result)
            
            # é¡¯ç¤ºçµæœ
            cv2.imshow('emotion detection system (q: quit)', annotated_frame)
            
            # æŒ‰ 'q' é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ¶ä¸­æ–·ç¨‹åº")
    
    finally:
        # æ¸…ç†è³‡æº
        cap.release()
        cv2.destroyAllWindows()
        print("\nç¨‹åºå·²é—œé–‰")


if __name__ == '__main__':
    main()
